{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data in Shape\n",
    "##### This notebook ingests the NYCDOE School Quality Reports from the past two years and produces a single table combining columns from multiple sheets across the origin xlsx files. It also adds a school year column to the final dataset to easily distinguish between the two years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import needed libraries. Assumes env.yml in parent folder has been activated. \n",
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here, I create variables that indicate which sheets and columns to keep from the data files. Since there are slight variations in the column names for the graduation metrics, I explictly names them for ease of ingestion. In the future, I'd like to come up with a clever way to regex for these columns across both tables, similiar to what I've done for the summary sheet information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUrls= [\"http://schools.nyc.gov/NR/rdonlyres/32595FE4-15E0-4DFE-A4F4-2D9AD32ED6D1/0/2015_2016_HS_SQR_Results_2017_01_05.xlsx\",\n",
    "          \"http://schools.nyc.gov/NR/rdonlyres/CDB6D687-3DAB-4B0D-8DC7-0EF7784E7C3B/0/201617_HS_SQR_Results_2018_01_22.xlsx\"]\n",
    "dataSheets = [\"Summary\",\"Student Achievement\",\"Closing the Achievement Gap\"]\n",
    "summaryColsRegex = \"(?<!Trust)Percent (?!Positive|of|Overage)|(8)|Economic|Name|Type|Enrollment\"\n",
    "achievement1516 = ['School Name','Metric Value - Graduation Rate, 4 year',\n",
    "                  'Metric Value - College and Career Preparatory Course Index']\n",
    "achievement1617 = ['School Name','Metric Value - 4-Year Graduation Rate',\n",
    "                 'Metric Value - College and Career Preparatory Course Index']\n",
    "closing1516 = ['School Name','Metric Value - Graduation Rate, 4-year, Self-Contained, CTT, or SETSS',\n",
    "               'Metric Value - Graduation Rate, 4-year, ELL',\n",
    "               'Metric Value - Graduation Rate, 4-year, lowest third city']\n",
    "closing1617 = ['School Name','Metric Value - 4-Year Graduation Rate - Self-Contained, Integrated Co-Teaching, or SETSS',\n",
    "            'Metric Value - 4-Year Graduation Rate - English Language Learners',\n",
    "            'Metric Value - 4-Year Graduation Rate - Lowest Third Citywide']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a part of cleaning, I want to simplify the column names, so this function handles for the various quirks of this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanColumnNames(col):\n",
    "    col = col.replace(\"Metric Value -\", \"\")\n",
    "    col = col.replace(\" \", \"\")\n",
    "    col = col.replace(\"-\", \"\")\n",
    "    col = col.replace(\",\", \"\")\n",
    "    col = col[0].lower() + col[1:]\n",
    "    return(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, I create a custom cleaning function that downloads the data, reads in the required sheets and subsets to the correct columns. It then cbinds the various data sources together and adds a school year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSqr(url):\n",
    "    temp = pd.read_excel(io=url,sheet_name = dataSheets,header=1)\n",
    "    year = re.search(\"(?<=/0/)(.*)(?=_HS)\",url)[0]\n",
    "    temp[\"Summary\"] = temp[\"Summary\"].filter(regex = summaryColsRegex)\n",
    "    if year == \"201617\" :\n",
    "        temp[\"Student Achievement\"] = temp[\"Student Achievement\"].filter(achievement1617)\n",
    "        temp[\"Closing the Achievement Gap\"] = temp[\"Closing the Achievement Gap\"].filter(closing1617)\n",
    "    else :\n",
    "        temp[\"Student Achievement\"] = temp[\"Student Achievement\"].filter(achievement1516)\n",
    "        temp[\"Closing the Achievement Gap\"] = temp[\"Closing the Achievement Gap\"].filter(closing1516)\n",
    "    dfs = [temp[\"Summary\"],temp]\n",
    "    full = reduce(lambda left,right: pd.merge(left,right,on='School Name'), temp.values())\n",
    "    colNames = list(full)\n",
    "    newNames = [cleanColumnNames(col) for col in colNames]\n",
    "    columnDict = {k: v for k, v in zip(colNames, newNames)}\n",
    "    full = full.rename(columns = columnDict)\n",
    "    full['schoolYear'] = year\n",
    "    return(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this step, I use list comprehension to iterate my function over the list of urls. While the list is not large now, this method can easily scale to much larger list of data. I also rename the columns in the two datasets to match. After doing so, I run a few lines of code to confirm that the dataframes are the same shape and have the same column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqr1516, sqr1617 = [cleanSqr(x) for x in dataUrls]\n",
    "update1516 = {k: v for k, v in zip(list(sqr1516), list(sqr1617))}\n",
    "sqr1516 = sqr1516.rename(columns = update1516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s15 = set(list(sqr1516))\n",
    "s16 = set(list(sqr1617))\n",
    "s15.symmetric_difference(s16) # This should return an empty set to ensure data column equivalency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, I row bind the two years of data into a single dataframe to save. This will be the dataset I use going forward in analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = list(sqr1516)\n",
    "sqr1617 = sqr1617[colList] #this ensures the columns are in the same order before appending\n",
    "finalData = sqr1516.append(sqr1617)\n",
    "finalData.to_csv(path_or_buf=\"/Users/Triveni/Desktop/dataScience/data/sqrAnalysisData.csv\",index=False) \n",
    "#If you are running this notebook, change the path_or_buf argument to fit your desired save location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
